{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 160, 160, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 158, 158, 16)      160       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 158, 158, 16)      64        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 158, 158, 16)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 40, 40, 16)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 38, 38, 32)        4640      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 38, 38, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 38, 38, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 19, 19, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 17, 17, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 17, 17, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 17, 17, 64)        0         \n",
      "                                                                 \n",
      " average_pooling2d (Average  (None, 9, 9, 64)          0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5184)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               1327360   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1417153 (5.41 MB)\n",
      "Trainable params: 1416929 (5.41 MB)\n",
      "Non-trainable params: 224 (896.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "\n",
    "def create_model(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # First layer\n",
    "    conv1 = tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), strides=(1, 1),kernel_regularizer=tf.keras.regularizers.l2(0.001) ,padding='valid')(inputs)\n",
    "    batchnorm1 = tf.keras.layers.BatchNormalization()(conv1)\n",
    "    relu1 = tf.keras.layers.ReLU()(batchnorm1)\n",
    "    maxpool1 = tf.keras.layers.MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same')(relu1)\n",
    "    \n",
    "    # Second layer\n",
    "    conv2 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1),kernel_regularizer=tf.keras.regularizers.l2(0.001) ,padding='valid')(maxpool1)\n",
    "    batchnorm2 = tf.keras.layers.BatchNormalization()(conv2)\n",
    "    relu2 = tf.keras.layers.ReLU()(batchnorm2)\n",
    "    maxpool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(relu2)\n",
    "    \n",
    "    # Third layer\n",
    "    conv3 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1),kernel_regularizer=tf.keras.regularizers.l2(0.001), padding='valid')(maxpool2)\n",
    "    batchnorm3 = tf.keras.layers.BatchNormalization()(conv3)\n",
    "    relu3 = tf.keras.layers.ReLU()(batchnorm3)\n",
    "    avgpool = tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(relu3)\n",
    "    \n",
    "    # Flatten the output of the last convolutional layer\n",
    "    flatten = tf.keras.layers.Flatten()(avgpool)\n",
    "    \n",
    "    # Fully connected layers\n",
    "    fc1 = tf.keras.layers.Dense(256, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.001))(flatten)\n",
    "    fc2 = tf.keras.layers.Dense(256, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.001))(fc1)\n",
    "\n",
    "    # Output layer (binary classification)\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid')(fc2)\n",
    "    \n",
    "    # Create the model\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "input_shape = (160, 160, 1)  \n",
    "\n",
    "model = create_model(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder1_path = '.\\persons\\person1'\n",
    "folder2_path = '.\\persons\\person2'\n",
    "\n",
    "def load_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img = cv2.imread(os.path.join(folder_path, filename),cv2.COLOR_BGR2GRAY)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "images_for_person1 = load_images_from_folder(folder1_path)\n",
    "images_for_person2 = load_images_from_folder(folder2_path)\n",
    "\n",
    "\n",
    "indices_to_separate = [2,5,10,11,12,13,15,39,40,41,42,44]\n",
    "\n",
    "#Separating indices for person 1\n",
    "testing_indices_person1 = indices_to_separate.copy()\n",
    "testing_images_person1 = [images_for_person1[i] for i in testing_indices_person1]\n",
    "remaining_indices_person1 = np.setdiff1d(np.arange(len(images_for_person1)), testing_indices_person1)\n",
    "training_images_person1 = [images_for_person1[i] for i in remaining_indices_person1]\n",
    "\n",
    "# Separating indices for person 2\n",
    "testing_indices_person2 = indices_to_separate.copy()\n",
    "testing_images_person2 = [images_for_person2[i] for i in testing_indices_person2]\n",
    "remaining_indices_person2 = np.setdiff1d(np.arange(len(images_for_person2)), testing_indices_person2)\n",
    "training_images_person2 = [images_for_person2[i] for i in remaining_indices_person2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform image sharpening\n",
    "def sharpen_image(image):\n",
    "    kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "    sharpened = cv2.filter2D(image, -1, kernel)\n",
    "    return sharpened\n",
    "\n",
    "# Function to perform image flipping\n",
    "def flip_image(image):\n",
    "    flipped = cv2.flip(image, 1)  # 1 for vertical flipping\n",
    "    return flipped\n",
    "\n",
    "# Perform data augmentation for person 1\n",
    "augmented_training_images_person1 = []\n",
    "for image in training_images_person1:\n",
    "    sharpened_image = sharpen_image(image)\n",
    "    flipped_image = flip_image(image)\n",
    "    augmented_training_images_person1.append(sharpened_image)\n",
    "    augmented_training_images_person1.append(flipped_image)\n",
    "\n",
    "# Perform data augmentation for person 2\n",
    "augmented_training_images_person2 = []\n",
    "for image in training_images_person2:\n",
    "    sharpened_image = sharpen_image(image)\n",
    "    flipped_image = flip_image(image)\n",
    "    augmented_training_images_person2.append(sharpened_image)\n",
    "    augmented_training_images_person2.append(flipped_image)\n",
    "             \n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "augmented_training_images_person1 = np.array(augmented_training_images_person1)\n",
    "augmented_training_images_person2 = np.array(augmented_training_images_person2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data to feeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate the 2 training array and labeling crossponding index in y_train\n",
    "X_train = np.concatenate((augmented_training_images_person1, augmented_training_images_person2))\n",
    "y_train = np.concatenate((\n",
    "    np.zeros(len(augmented_training_images_person1)),\n",
    "    np.ones(len(augmented_training_images_person2))\n",
    "))\n",
    "\n",
    "# Shuffle the data\n",
    "shuffle_indices = np.random.permutation(len(X_train))\n",
    "X_train_shuffled = X_train[shuffle_indices]\n",
    "y_train_shuffled = y_train[shuffle_indices]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "okernel",
   "language": "python",
   "name": "okernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
